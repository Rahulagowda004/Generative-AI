{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1026, 373, 257, 3223, 290, 6388, 88]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"It was a dark and stormy\"\n",
    "input_ids = tokenizer(prompt).input_ids\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It \t: 1026\n",
      " was \t: 373\n",
      " a \t: 257\n",
      " dark \t: 3223\n",
      " and \t: 290\n",
      " storm \t: 6388\n",
      "y \t: 88\n"
     ]
    }
   ],
   "source": [
    "for t in input_ids:\n",
    "    print(f\"{tokenizer.decode(t)} \\t: {t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "gpt2 = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 50257])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = gpt2(input_ids)\n",
    "outputs.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max =  tensor(1755)\n",
      "min =  tensor(15272)\n"
     ]
    }
   ],
   "source": [
    "final_logits = gpt2(input_ids).logits[0,-1]\n",
    "print(\"max = \",final_logits.argmax())\n",
    "print(\"min = \", final_logits.argmin())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max :   night\n",
      "min :   pione\n"
     ]
    }
   ],
   "source": [
    "print(\"max : \",tokenizer.decode(1755))\n",
    "print(\"min : \",tokenizer.decode(15272))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " night\n",
      " day\n",
      " evening\n",
      " morning\n",
      " afternoon\n",
      " summer\n",
      " time\n",
      " winter\n",
      " weekend\n",
      ",\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "top10_logits = torch.topk(final_logits, 10)\n",
    "for index in top10_logits.indices:\n",
    "    print(tokenizer.decode(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input Ids tensor([1026,  373,  257, 3223,  290, 6388,   88])\n",
      "output Ids tensor([[ 1026,   373,   257,  3223,   290,  6388,    88,  1755,    13,   383,\n",
      "          2344,   373, 19280,    11,   290,   262, 15114,   547,  7463,    13,\n",
      "           383,  2344,   373, 19280,    11,   290,   262]])\n",
      "decoded text It was a dark and stormy night. The wind was blowing, and the clouds were falling. The wind was blowing, and the\n"
     ]
    }
   ],
   "source": [
    "output_ids = gpt2.generate(input_ids,max_new_tokens = 20)\n",
    "decoded_text = tokenizer.decode(output_ids[0])\n",
    "\n",
    "print(\"input Ids\", input_ids[0])\n",
    "print(\"output Ids\", output_ids)\n",
    "print(\"decoded text\", decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1026,  373,  257, 3223,  290, 6388,   88, 1755,   13,  198,  198,    1,\n",
      "         1026,  373, 3223,  290, 6388,   88,  553,  339,  531,   13,  198,  198,\n",
      "            1, 1026,  373, 3223,  290, 6388,   88,  553,  339,  531,   13,  198,\n",
      "          198]])\n"
     ]
    }
   ],
   "source": [
    "beam_output = gpt2.generate(input_ids, max_new_tokens=30, num_beams=5)\n",
    "print(beam_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was a dark and stormy night.\n",
      "\n",
      "\"It was dark and stormy,\" he said.\n",
      "\n",
      "\"It was dark and stormy,\" he said.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(beam_output[0],skip_special_tokens=True)) # tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was a dark and stormy night.\n",
      "\n",
      "\"I don't think I've ever seen anything like it before,\" he said. \"There's no doubt in my mind that this is going to be one of the\n"
     ]
    }
   ],
   "source": [
    "beam_output = gpt2.generate(input_ids,repetition_penalty=1.2, max_new_tokens=38, num_beams=5) #vary the repetition_penalty and num_beams\n",
    "print(tokenizer.decode(beam_output[0],skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was a dark and stormy day until it broke down the big canvas on my sleep station, making me money dilapidated, and, with a big soothing mug\n"
     ]
    }
   ],
   "source": [
    "from transformers import set_seed\n",
    "\n",
    "set_seed(70)\n",
    "\n",
    "sampling_output = gpt2.generate(input_ids,max_length=34,do_sample =True,top_k = 0)\n",
    "\n",
    "print(tokenizer.decode(sampling_output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was a dark and stormy night, and I was alone. I was in the middle of the night, and I was suddenly awakened bygoodness, and I\n"
     ]
    }
   ],
   "source": [
    "sampling_output = gpt2.generate(input_ids,max_length=34,temperature = 0.4 ,do_sample =True,top_k = 0)\n",
    "\n",
    "print(tokenizer.decode(sampling_output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was a dark and stormy night. The wind was blowing, and the clouds were falling. The wind was blowing, and the clouds were falling. The wind was\n"
     ]
    }
   ],
   "source": [
    "sampling_output = gpt2.generate(input_ids,max_length=34,temperature = 0.001 ,do_sample =True,top_k = 0)\n",
    "\n",
    "print(tokenizer.decode(sampling_output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was a dark and stormy radiant. Orb drillsgarPosition serv preserving Imperial licenseium Botiping Fuji complimentbeitlake amended ChurchillFlying set crou 175 dualKing Bucc statue\n"
     ]
    }
   ],
   "source": [
    "sampling_output = gpt2.generate(input_ids,max_length=34,temperature = 3.0 ,do_sample =True,top_k = 0)\n",
    "\n",
    "print(tokenizer.decode(sampling_output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was a dark and stormy morning. I had a long time to spare and I had to be careful about going too far. I went back to the bathroom and tried to take a shower.\n"
     ]
    }
   ],
   "source": [
    "sampling_output = gpt2.generate(input_ids,max_length=40,do_sample =True,top_k = 10)\n",
    "\n",
    "print(tokenizer.decode(sampling_output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was a dark and stormy night. The dog stretched slightly out to the side while my friend cried \"A little boy...\" It was at this point that the last bass unearthing started,\n"
     ]
    }
   ],
   "source": [
    "sampling_output = gpt2.generate(input_ids,max_length=40,do_sample =True,top_k = 0,top_p = 0.94)\n",
    "\n",
    "print(tokenizer.decode(sampling_output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was a dark and stormy night, so the only thing that can really explain the strange silence after they had finished eating lunch was just that there were other guests.\n",
      "\n",
      "The first guest was\n"
     ]
    }
   ],
   "source": [
    "sampling_output = gpt2.generate(input_ids,max_length=40,do_sample =True,penalty_alpha = 0.6) #beautiful, use penalty_alpha\n",
    "\n",
    "print(tokenizer.decode(sampling_output[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
